[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "An Empirical Analysis of the Effects of Inflation and Exchange Rate Volatility on Brain Drain in Turkey (2021–2023)",
    "section": "",
    "text": "Takım Üyesi / Üyeleri: 1.Batıhan KONUK - [N24141171] 2.Ali Burak AKBULUT - [N24142785]\nWelcome to our project page for EMU660 – Decision Making with Analytics.\nThis project investigates the impact of inflation and exchange rate fluctuations on the brain drain of highly educated individuals from Turkey between 2021 and 2023."
  },
  {
    "objectID": "project.html#data-source",
    "href": "project.html#data-source",
    "title": "Türkiye’de Enflasyon ve Döviz Kurunun Beyin Göçüne Etkisi (2021–2023)",
    "section": "2.1 Data Source",
    "text": "2.1 Data Source\nEconomic Data Sources: - Turkish Statistical Institute (TÜİK) - Central Bank of the Republic of Turkey (TCMB)\nBrain Drain Data Source: - TÜİK – “Higher Education Brain Drain Statistics (as of 2023)”"
  },
  {
    "objectID": "project.html#general-information-about-data",
    "href": "project.html#general-information-about-data",
    "title": "Türkiye’de Enflasyon ve Döviz Kurunun Beyin Göçüne Etkisi (2021–2023)",
    "section": "2.2 General Information About Data",
    "text": "2.2 General Information About Data\nEconomic Variables (2021–2023): - Annual Inflation Rate (based on CPI, December-based) - Exchange Rate (TRY/USD, annual average) - Unemployment Rate (used as a control variable, if available)\nBrain Drain Variables (2015–2023): - Graduation year-based migration rates (for 2000–2017 graduates) - Gender-based distribution (Male/Female) - Education fields (STEM, Social Sciences, etc.) - Major/program-based breakdown (e.g., Computer Engineering, Molecular Biology) - Top destination countries (e.g., USA, Germany, Netherlands, Canada) - Country-major matchups for top 5 destinations"
  },
  {
    "objectID": "project.html#reason-of-choice",
    "href": "project.html#reason-of-choice",
    "title": "An Empirical Analysis of the Effects of Inflation and Exchange Rate Volatility on Brain Drain in Turkey (2021–2023)",
    "section": "2.3 Reason of Choice",
    "text": "2.3 Reason of Choice\nThis topic is highly relevant due to increasing concern about qualified youth leaving the country in response to economic uncertainties. The selected data offers both depth and breadth to explore not only economic correlations but also the demographic and academic patterns that characterize this migration."
  },
  {
    "objectID": "project.html#preprocessing",
    "href": "project.html#preprocessing",
    "title": "An Empirical Analysis of the Effects of Inflation and Exchange Rate Volatility on Brain Drain in Turkey (2021–2023)",
    "section": "2.4 Preprocessing",
    "text": "2.4 Preprocessing\n\nData were obtained in .xlsx format.\nCleaned using R with packages: readxl, dplyr, lubridate, janitor, and ggplot2.\nMissing and outlier values were removed.\nVariables were recoded and merged by year, department, and country.\nFinal cleaned dataset is saved in .RData format."
  },
  {
    "objectID": "project.html#exploratory-data-analysis",
    "href": "project.html#exploratory-data-analysis",
    "title": "An Empirical Analysis of the Effects of Inflation and Exchange Rate Volatility on Brain Drain in Turkey (2021–2023)",
    "section": "3.1 Exploratory Data Analysis",
    "text": "3.1 Exploratory Data Analysis\n\nHistograms for distributions of inflation, exchange rate, and migration rate\nBoxplots for gender and graduation year-based comparisons\nTime series plots for trends in migration, inflation, and exchange rate\nScatter plots with regression lines to observe relationships visually"
  },
  {
    "objectID": "project.html#trend-analysis",
    "href": "project.html#trend-analysis",
    "title": "An Empirical Analysis of the Effects of Inflation and Exchange Rate Volatility on Brain Drain in Turkey (2021–2023)",
    "section": "3.2 Trend Analysis",
    "text": "3.2 Trend Analysis\n\nMigration trends by gender and graduation year\nSectoral breakdown of brain drain (e.g., STEM vs Social Sciences)\nDestination country analysis with academic background of migrants"
  },
  {
    "objectID": "project.html#model-fitting",
    "href": "project.html#model-fitting",
    "title": "An Empirical Analysis of the Effects of Inflation and Exchange Rate Volatility on Brain Drain in Turkey (2021–2023)",
    "section": "3.3 Model Fitting",
    "text": "3.3 Model Fitting\n\nCorrelation coefficients between economic indicators and migration\nMultiple Linear Regression Model:\n\nDependent Variable: Migration Rate\nIndependent Variables: Inflation, Exchange Rate, Unemployment Rate"
  },
  {
    "objectID": "project.html#results",
    "href": "project.html#results",
    "title": "An Empirical Analysis of the Effects of Inflation and Exchange Rate Volatility on Brain Drain in Turkey (2021–2023)",
    "section": "3.4 Results",
    "text": "3.4 Results\n\nPositive correlation found between inflation and migration (r = 0.91)\nStrong relationship between exchange rate and migration (r = 0.88)\nRegression model significant (p &lt; 0.05, R² &gt; 0.85)\nTop migration destinations: Germany, USA, UK, Netherlands, Canada\nSTEM fields show highest migration rates (&gt;10% in some programs)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello!! My name is Batıhan KONUK.\nThis is my personal webpage.\nPlease stay tuned to follow my works on data analytics, blog posts, and more.\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Assignment 2\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\n\nPhilip Morris International, position EZD Merchandiser , year 2015\nYapı ve Kredi Bankası A.Ş., position Coorparate Banking Assistant Specialist, year 2020\nTÜBİTAK, position Scientific Program Expert, year 2021 - ongoing"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nGaranti Yatırım A.Ş., position Finance Intern, year 2018\nTürk Traktör A.Ş. position Mentor, year 2019 - 2020"
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n\nMy first assignment has two parts.\n\n\nBu sohbette Boğaziçi Üniversitesi Endüstri Mühendisliği Bölümü’nde öğretim üyesi olan ve aynı zamanda Alg Foli Software and Consulting Incorporated Company’nin kurucusu Doç. Dr. Mustafa Baydoğan; veri bilimi, makine öğrenmesi, optimizasyon ve endüstri mühendisliği uygulamalarına ilişkin çeşitli konulara değinmiştir. Akademik kariyerinden ve uzmanlık alanlarından söz ederken, veri analitiği, tahmin (prediction) yöntemleri ve karar destek sistemlerine odaklandığından bahsetmiştir.\nÖncelikle endüstri mühendisliğinin temel amaçlarından biri olan problem çözme süreci ele alınmış olup, endüstri mühendislerinin karşılaştığı problemlerin çoğunlukla optimizasyon ve veri analitiği yaklaşımlarıyla çözüldüğü, bu kapsamda matematiksel modelleme, simülasyon ve olasılıksal yöntemler gibi tekniklerin kullanıldığı belirtilmiştir. Veri bilimi ile endüstri mühendisliği disiplinlerinin giderek daha fazla iç içe geçtiğinin altı çizilerek, büyük ölçekli problemlerin daha etkili yöntemlerle ele alınabileceği vurgulanmıştır.\nDaha sonra tahmin ve optimizasyon tekniklerine yoğunlaşılmış, zaman serisi tahminleri, makine öğrenmesi ve veri madenciliği gibi konuların özellikle perakende sektöründe talep tahmini ve stok yönetimi sorunlarına nasıl çözüm sağladığı aktarılmıştır. Geleneksel tahmin yöntemleri ile derin öğrenmeye dayalı modeller karşılaştırıldığında makine öğrenmesinin avantajlarının bir hayli yüksek olduğundan bahsedilmiştir. Ayrıca, karar destek sistemlerindeki saydamlık açısından “açıklanabilir yapay zekâ” kavramının giderek daha büyük önem kazandığı ifade edilmiştir.\nSunumun ilerleyen kısmında, karar destek sistemlerinin lojistik ve enerji sektörlerinde nasıl kullanıldığı ayrıntılı biçimde incelenmiştir. Özellikle elektrik piyasasında üretim ve tüketim arasındaki dengenin sağlanması amacıyla yürütülen tahmin çalışmalarının önemi, yanıltıcı tahminlerin sektöre getirebileceği ekonomik zararlar çerçevesinde ele alınmış olup, enerji tahmin modellerinde makine öğrenmesinin oynadığı rol ve hata payını en aza indiren algoritmaların geliştirilmesinin gerekliliği ve önemi vurgulanmıştır.\nBununla birlikte, derin öğrenme ve yapılandırılmamış verilerin işlenmesi konularına da değinilmiştir. Geleneksel makine öğrenmesi yöntemleriyle derin öğrenme modelleri karşılaştırılarak, görüntü işleme ve metin analizi gibi yapılandırılmamış veri alanlarında derin öğrenmenin daha etkili olduğu vurgulandmış ve bu modellerde yorumlanabilirliğin güç olabildiği ve iş dünyasında karar alma süreçlerinde açıklanabilir modellere giderek daha çok ihtiyaç duyulduğuna dikkat çekilmiştir.\nAyrıca, makine öğrenmesi tekniklerinin optimizasyon problemlerine nasıl entegre edilebileceği de ele alınmıştır. Özellikle tamsayılı programlama gibi karmaşık optimizasyon sorunlarında, geçmiş çözümlerden elde edilen bilgiyle optimizasyon süreçlerinin hızlandırılabildiği ifade edilmiştir. Bu yaklaşımın, geniş lojistik operasyonları bulunan şirketler tarafından süreçleri daha verimli hâle getirmek amacıyla aktif bir biçimde araştırıldığı aktarılmıştır.\nSon bölümde ise veri bilimi ile optimizasyonun yakınsamasına dair bir değerlendirme yapılmıştır ve akademik çalışmaların endüstriyel uygulamalara katabileceği değerin bir hayli yüksek olduğu vurgulanmıştır. Açıklanabilir yapay zekâ, veri kalitesi ve sağlam tahmin (robust forecasting) tekniklerinin gelecekte daha fazla önem kazanacağı belirtilmiştir. Veri bilimi alanında uzmanlaşmak isteyenlerin sadece teorik bilgiyle yetinmeyip farklı sektörlerde pratik deneyim edinmelerinin kritik olduğu da özellikle ifade edilmiştir.\n\n\n\n\ndata(mtcars)\nprint(colnames(mtcars))\n\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\"\n\ncompute_stats &lt;- function(b) {\n  list(\n    mean = mean(b, na.rm = TRUE),\n    median = median(b, na.rm = TRUE),\n    variance = var(b, na.rm = TRUE),\n    IQR = IQR(b, na.rm = TRUE),\n    min = min(b, na.rm = TRUE),\n    max = max(b, na.rm = TRUE)\n  )\n}\n\n\nfor (col in names(mtcars)) {\n  if (is.numeric(mtcars[[col]])) {  \n    cat(\"\\nStatistics for:\", col, \"\\n\")\n    print(compute_stats(mtcars[[col]]))\n  }\n}\n\n\nStatistics for: mpg \n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n\nStatistics for: cyl \n$mean\n[1] 6.1875\n\n$median\n[1] 6\n\n$variance\n[1] 3.189516\n\n$IQR\n[1] 4\n\n$min\n[1] 4\n\n$max\n[1] 8\n\n\nStatistics for: disp \n$mean\n[1] 230.7219\n\n$median\n[1] 196.3\n\n$variance\n[1] 15360.8\n\n$IQR\n[1] 205.175\n\n$min\n[1] 71.1\n\n$max\n[1] 472\n\n\nStatistics for: hp \n$mean\n[1] 146.6875\n\n$median\n[1] 123\n\n$variance\n[1] 4700.867\n\n$IQR\n[1] 83.5\n\n$min\n[1] 52\n\n$max\n[1] 335\n\n\nStatistics for: drat \n$mean\n[1] 3.596563\n\n$median\n[1] 3.695\n\n$variance\n[1] 0.2858814\n\n$IQR\n[1] 0.84\n\n$min\n[1] 2.76\n\n$max\n[1] 4.93\n\n\nStatistics for: wt \n$mean\n[1] 3.21725\n\n$median\n[1] 3.325\n\n$variance\n[1] 0.957379\n\n$IQR\n[1] 1.02875\n\n$min\n[1] 1.513\n\n$max\n[1] 5.424\n\n\nStatistics for: qsec \n$mean\n[1] 17.84875\n\n$median\n[1] 17.71\n\n$variance\n[1] 3.193166\n\n$IQR\n[1] 2.0075\n\n$min\n[1] 14.5\n\n$max\n[1] 22.9\n\n\nStatistics for: vs \n$mean\n[1] 0.4375\n\n$median\n[1] 0\n\n$variance\n[1] 0.2540323\n\n$IQR\n[1] 1\n\n$min\n[1] 0\n\n$max\n[1] 1\n\n\nStatistics for: am \n$mean\n[1] 0.40625\n\n$median\n[1] 0\n\n$variance\n[1] 0.2489919\n\n$IQR\n[1] 1\n\n$min\n[1] 0\n\n$max\n[1] 1\n\n\nStatistics for: gear \n$mean\n[1] 3.6875\n\n$median\n[1] 4\n\n$variance\n[1] 0.5443548\n\n$IQR\n[1] 1\n\n$min\n[1] 3\n\n$max\n[1] 5\n\n\nStatistics for: carb \n$mean\n[1] 2.8125\n\n$median\n[1] 2\n\n$variance\n[1] 2.608871\n\n$IQR\n[1] 2\n\n$min\n[1] 1\n\n$max\n[1] 8\n\nstatistics_sapply &lt;- sapply(mtcars, compute_stats)\n\nprint(\"Applying compute_stats Using sapply()\")\n\n[1] \"Applying compute_stats Using sapply()\"\n\nprint(statistics_sapply)\n\n         mpg      cyl      disp     hp       drat      wt       qsec    \nmean     20.09062 6.1875   230.7219 146.6875 3.596563  3.21725  17.84875\nmedian   19.2     6        196.3    123      3.695     3.325    17.71   \nvariance 36.3241  3.189516 15360.8  4700.867 0.2858814 0.957379 3.193166\nIQR      7.375    4        205.175  83.5     0.84      1.02875  2.0075  \nmin      10.4     4        71.1     52       2.76      1.513    14.5    \nmax      33.9     8        472      335      4.93      5.424    22.9    \n         vs        am        gear      carb    \nmean     0.4375    0.40625   3.6875    2.8125  \nmedian   0         0         4         2       \nvariance 0.2540323 0.2489919 0.5443548 2.608871\nIQR      1         1         1         2       \nmin      0         0         3         1       \nmax      1         1         5         8       \n\nstatistics_apply &lt;- apply(mtcars, MARGIN = 2, compute_stats)\nprint(\"Applying compute_stats Using apply()\")\n\n[1] \"Applying compute_stats Using apply()\"\n\nprint(statistics_apply)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$max\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$max\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$max\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$max\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$max\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$max\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$max\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$max\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$max\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$max\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$max\n[1] 8\n\n\n\n\n\n\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.3.3\n\ndata(\"na_example\")\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\nna_count &lt;- sum(is.na(na_example))\nprint(na_count) #Total NA values\n\n[1] 145\n\nna_indic &lt;- which(is.na(na_example))\nprint(na_indic) #Indices of NA values\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\nbefore_mean &lt;- mean(na_example, na.rm = TRUE) #mean ignoring NA values\nprint(before_mean) #Mean before handling NA values\n\n[1] 2.301754\n\nbefore_sd &lt;- sd(na_example, na.rm = TRUE)  #standard deviation ignoring NA values\nprint(before_sd) #Standard Deviation before handling NA values\n\n[1] 1.22338\n\nmedian_value &lt;- median(na_example, na.rm = TRUE) # Compute the median of non-missing values\n\n\nna_replaced_median &lt;- na_example\nna_replaced_median[is.na(na_replaced_median)] &lt;- median_value # Replace NA values with the median\n\n\nnon_na_values &lt;- na_example[!is.na(na_example)]\nrandom_values &lt;- sample(non_na_values, size = sum(is.na(na_example)), replace = TRUE) # Select a random non-missing value\n\n\nna_replaced_random &lt;- na_example\nna_replaced_random[is.na(na_replaced_random)] &lt;- random_values # Replace NA values with random values\n\n\n# Version 1 (NA replaced with median)\nmean_median &lt;- mean(na_replaced_median)  #mean- NA replaced with median\nprint(mean_median)   #Mean after replacing NA with median\n\n[1] 2.258\n\nsd_median &lt;- sd(na_replaced_median)  #standard deviation- NA replaced with median\nprint(sd_median)  # Standard Deviation after replacing NA with median\n\n[1] 1.136102\n\n# Version 2 (NA replaced with random values)\nmean_random &lt;- mean(na_replaced_random)\nprint(mean_random) #Mean after replacing NA with random values\n\n[1] 2.312\n\nsd_random &lt;- sd(na_replaced_random)\nprint(sd_random) #Standard Deviation after replacing NA with random values\n\n[1] 1.228073\n\n\"Yorumlar\"\n\n[1] \"Yorumlar\"\n\n\"Bu veri seti için eksik verilerin rastgele mevcut değerlerle doldurulması yöntemi daha uygun görünmektedir. Bunun nedeni, bu yöntemin veri setinin ortalama ve standart sapma değerlerini koruyarak orijinal veri yapısının bozulmasını en aza indirmesidir. Öte yandan, medyan ile doldurma yöntemi veri setinin varyansını azaltarak veri dağılımını değiştirmiş ve olası bilgi kaybına neden olmuştur.\"\n\n[1] \"Bu veri seti için eksik verilerin rastgele mevcut değerlerle doldurulması yöntemi daha uygun görünmektedir. Bunun nedeni, bu yöntemin veri setinin ortalama ve standart sapma değerlerini koruyarak orijinal veri yapısının bozulmasını en aza indirmesidir. Öte yandan, medyan ile doldurma yöntemi veri setinin varyansını azaltarak veri dağılımını değiştirmiş ve olası bilgi kaybına neden olmuştur.\"",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#a-veri-bilimi-ve-endüstri-mühendisliği-üzerine-sohbetler--mustafa-baydoğan-erdi-daşdemir",
    "href": "assignments/assignment-1.html#a-veri-bilimi-ve-endüstri-mühendisliği-üzerine-sohbetler--mustafa-baydoğan-erdi-daşdemir",
    "title": "Assignment 1",
    "section": "",
    "text": "Bu sohbette Boğaziçi Üniversitesi Endüstri Mühendisliği Bölümü’nde öğretim üyesi olan ve aynı zamanda Alg Foli Software and Consulting Incorporated Company’nin kurucusu Doç. Dr. Mustafa Baydoğan; veri bilimi, makine öğrenmesi, optimizasyon ve endüstri mühendisliği uygulamalarına ilişkin çeşitli konulara değinmiştir. Akademik kariyerinden ve uzmanlık alanlarından söz ederken, veri analitiği, tahmin (prediction) yöntemleri ve karar destek sistemlerine odaklandığından bahsetmiştir.\nÖncelikle endüstri mühendisliğinin temel amaçlarından biri olan problem çözme süreci ele alınmış olup, endüstri mühendislerinin karşılaştığı problemlerin çoğunlukla optimizasyon ve veri analitiği yaklaşımlarıyla çözüldüğü, bu kapsamda matematiksel modelleme, simülasyon ve olasılıksal yöntemler gibi tekniklerin kullanıldığı belirtilmiştir. Veri bilimi ile endüstri mühendisliği disiplinlerinin giderek daha fazla iç içe geçtiğinin altı çizilerek, büyük ölçekli problemlerin daha etkili yöntemlerle ele alınabileceği vurgulanmıştır.\nDaha sonra tahmin ve optimizasyon tekniklerine yoğunlaşılmış, zaman serisi tahminleri, makine öğrenmesi ve veri madenciliği gibi konuların özellikle perakende sektöründe talep tahmini ve stok yönetimi sorunlarına nasıl çözüm sağladığı aktarılmıştır. Geleneksel tahmin yöntemleri ile derin öğrenmeye dayalı modeller karşılaştırıldığında makine öğrenmesinin avantajlarının bir hayli yüksek olduğundan bahsedilmiştir. Ayrıca, karar destek sistemlerindeki saydamlık açısından “açıklanabilir yapay zekâ” kavramının giderek daha büyük önem kazandığı ifade edilmiştir.\nSunumun ilerleyen kısmında, karar destek sistemlerinin lojistik ve enerji sektörlerinde nasıl kullanıldığı ayrıntılı biçimde incelenmiştir. Özellikle elektrik piyasasında üretim ve tüketim arasındaki dengenin sağlanması amacıyla yürütülen tahmin çalışmalarının önemi, yanıltıcı tahminlerin sektöre getirebileceği ekonomik zararlar çerçevesinde ele alınmış olup, enerji tahmin modellerinde makine öğrenmesinin oynadığı rol ve hata payını en aza indiren algoritmaların geliştirilmesinin gerekliliği ve önemi vurgulanmıştır.\nBununla birlikte, derin öğrenme ve yapılandırılmamış verilerin işlenmesi konularına da değinilmiştir. Geleneksel makine öğrenmesi yöntemleriyle derin öğrenme modelleri karşılaştırılarak, görüntü işleme ve metin analizi gibi yapılandırılmamış veri alanlarında derin öğrenmenin daha etkili olduğu vurgulandmış ve bu modellerde yorumlanabilirliğin güç olabildiği ve iş dünyasında karar alma süreçlerinde açıklanabilir modellere giderek daha çok ihtiyaç duyulduğuna dikkat çekilmiştir.\nAyrıca, makine öğrenmesi tekniklerinin optimizasyon problemlerine nasıl entegre edilebileceği de ele alınmıştır. Özellikle tamsayılı programlama gibi karmaşık optimizasyon sorunlarında, geçmiş çözümlerden elde edilen bilgiyle optimizasyon süreçlerinin hızlandırılabildiği ifade edilmiştir. Bu yaklaşımın, geniş lojistik operasyonları bulunan şirketler tarafından süreçleri daha verimli hâle getirmek amacıyla aktif bir biçimde araştırıldığı aktarılmıştır.\nSon bölümde ise veri bilimi ile optimizasyonun yakınsamasına dair bir değerlendirme yapılmıştır ve akademik çalışmaların endüstriyel uygulamalara katabileceği değerin bir hayli yüksek olduğu vurgulanmıştır. Açıklanabilir yapay zekâ, veri kalitesi ve sağlam tahmin (robust forecasting) tekniklerinin gelecekte daha fazla önem kazanacağı belirtilmiştir. Veri bilimi alanında uzmanlaşmak isteyenlerin sadece teorik bilgiyle yetinmeyip farklı sektörlerde pratik deneyim edinmelerinin kritik olduğu da özellikle ifade edilmiştir.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#b",
    "href": "assignments/assignment-1.html#b",
    "title": "Assignment 1",
    "section": "",
    "text": "data(mtcars)\nprint(colnames(mtcars))\n\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\"\n\ncompute_stats &lt;- function(b) {\n  list(\n    mean = mean(b, na.rm = TRUE),\n    median = median(b, na.rm = TRUE),\n    variance = var(b, na.rm = TRUE),\n    IQR = IQR(b, na.rm = TRUE),\n    min = min(b, na.rm = TRUE),\n    max = max(b, na.rm = TRUE)\n  )\n}\n\n\nfor (col in names(mtcars)) {\n  if (is.numeric(mtcars[[col]])) {  \n    cat(\"\\nStatistics for:\", col, \"\\n\")\n    print(compute_stats(mtcars[[col]]))\n  }\n}\n\n\nStatistics for: mpg \n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n\nStatistics for: cyl \n$mean\n[1] 6.1875\n\n$median\n[1] 6\n\n$variance\n[1] 3.189516\n\n$IQR\n[1] 4\n\n$min\n[1] 4\n\n$max\n[1] 8\n\n\nStatistics for: disp \n$mean\n[1] 230.7219\n\n$median\n[1] 196.3\n\n$variance\n[1] 15360.8\n\n$IQR\n[1] 205.175\n\n$min\n[1] 71.1\n\n$max\n[1] 472\n\n\nStatistics for: hp \n$mean\n[1] 146.6875\n\n$median\n[1] 123\n\n$variance\n[1] 4700.867\n\n$IQR\n[1] 83.5\n\n$min\n[1] 52\n\n$max\n[1] 335\n\n\nStatistics for: drat \n$mean\n[1] 3.596563\n\n$median\n[1] 3.695\n\n$variance\n[1] 0.2858814\n\n$IQR\n[1] 0.84\n\n$min\n[1] 2.76\n\n$max\n[1] 4.93\n\n\nStatistics for: wt \n$mean\n[1] 3.21725\n\n$median\n[1] 3.325\n\n$variance\n[1] 0.957379\n\n$IQR\n[1] 1.02875\n\n$min\n[1] 1.513\n\n$max\n[1] 5.424\n\n\nStatistics for: qsec \n$mean\n[1] 17.84875\n\n$median\n[1] 17.71\n\n$variance\n[1] 3.193166\n\n$IQR\n[1] 2.0075\n\n$min\n[1] 14.5\n\n$max\n[1] 22.9\n\n\nStatistics for: vs \n$mean\n[1] 0.4375\n\n$median\n[1] 0\n\n$variance\n[1] 0.2540323\n\n$IQR\n[1] 1\n\n$min\n[1] 0\n\n$max\n[1] 1\n\n\nStatistics for: am \n$mean\n[1] 0.40625\n\n$median\n[1] 0\n\n$variance\n[1] 0.2489919\n\n$IQR\n[1] 1\n\n$min\n[1] 0\n\n$max\n[1] 1\n\n\nStatistics for: gear \n$mean\n[1] 3.6875\n\n$median\n[1] 4\n\n$variance\n[1] 0.5443548\n\n$IQR\n[1] 1\n\n$min\n[1] 3\n\n$max\n[1] 5\n\n\nStatistics for: carb \n$mean\n[1] 2.8125\n\n$median\n[1] 2\n\n$variance\n[1] 2.608871\n\n$IQR\n[1] 2\n\n$min\n[1] 1\n\n$max\n[1] 8\n\nstatistics_sapply &lt;- sapply(mtcars, compute_stats)\n\nprint(\"Applying compute_stats Using sapply()\")\n\n[1] \"Applying compute_stats Using sapply()\"\n\nprint(statistics_sapply)\n\n         mpg      cyl      disp     hp       drat      wt       qsec    \nmean     20.09062 6.1875   230.7219 146.6875 3.596563  3.21725  17.84875\nmedian   19.2     6        196.3    123      3.695     3.325    17.71   \nvariance 36.3241  3.189516 15360.8  4700.867 0.2858814 0.957379 3.193166\nIQR      7.375    4        205.175  83.5     0.84      1.02875  2.0075  \nmin      10.4     4        71.1     52       2.76      1.513    14.5    \nmax      33.9     8        472      335      4.93      5.424    22.9    \n         vs        am        gear      carb    \nmean     0.4375    0.40625   3.6875    2.8125  \nmedian   0         0         4         2       \nvariance 0.2540323 0.2489919 0.5443548 2.608871\nIQR      1         1         1         2       \nmin      0         0         3         1       \nmax      1         1         5         8       \n\nstatistics_apply &lt;- apply(mtcars, MARGIN = 2, compute_stats)\nprint(\"Applying compute_stats Using apply()\")\n\n[1] \"Applying compute_stats Using apply()\"\n\nprint(statistics_apply)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$max\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$max\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$max\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$max\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$max\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$max\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$max\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$max\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$max\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$max\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$max\n[1] 8",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the [term and year, e.g. Spring 2024-2025] EMU660 Decision Making with Analytics course.\nPlease use left menu to navigate through my assignments.\n\n\n\n Back to top",
    "crumbs": [
      "My Assignments"
    ]
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-1.html#c-displaying-and-manipulating-the-na_example-dataset",
    "href": "assignments/assignment-1.html#c-displaying-and-manipulating-the-na_example-dataset",
    "title": "Assignment 1",
    "section": "",
    "text": "library(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.3.3\n\ndata(\"na_example\")\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\nna_count &lt;- sum(is.na(na_example))\nprint(na_count) #Total NA values\n\n[1] 145\n\nna_indic &lt;- which(is.na(na_example))\nprint(na_indic) #Indices of NA values\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\nbefore_mean &lt;- mean(na_example, na.rm = TRUE) #mean ignoring NA values\nprint(before_mean) #Mean before handling NA values\n\n[1] 2.301754\n\nbefore_sd &lt;- sd(na_example, na.rm = TRUE)  #standard deviation ignoring NA values\nprint(before_sd) #Standard Deviation before handling NA values\n\n[1] 1.22338\n\nmedian_value &lt;- median(na_example, na.rm = TRUE) # Compute the median of non-missing values\n\n\nna_replaced_median &lt;- na_example\nna_replaced_median[is.na(na_replaced_median)] &lt;- median_value # Replace NA values with the median\n\n\nnon_na_values &lt;- na_example[!is.na(na_example)]\nrandom_values &lt;- sample(non_na_values, size = sum(is.na(na_example)), replace = TRUE) # Select a random non-missing value\n\n\nna_replaced_random &lt;- na_example\nna_replaced_random[is.na(na_replaced_random)] &lt;- random_values # Replace NA values with random values\n\n\n# Version 1 (NA replaced with median)\nmean_median &lt;- mean(na_replaced_median)  #mean- NA replaced with median\nprint(mean_median)   #Mean after replacing NA with median\n\n[1] 2.258\n\nsd_median &lt;- sd(na_replaced_median)  #standard deviation- NA replaced with median\nprint(sd_median)  # Standard Deviation after replacing NA with median\n\n[1] 1.136102\n\n# Version 2 (NA replaced with random values)\nmean_random &lt;- mean(na_replaced_random)\nprint(mean_random) #Mean after replacing NA with random values\n\n[1] 2.308\n\nsd_random &lt;- sd(na_replaced_random)\nprint(sd_random) #Standard Deviation after replacing NA with random values\n\n[1] 1.222551",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#c",
    "href": "assignments/assignment-1.html#c",
    "title": "Assignment 1",
    "section": "",
    "text": "library(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.3.3\n\ndata(\"na_example\")\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\nna_count &lt;- sum(is.na(na_example))\nprint(na_count) #Total NA values\n\n[1] 145\n\nna_indic &lt;- which(is.na(na_example))\nprint(na_indic) #Indices of NA values\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\nbefore_mean &lt;- mean(na_example, na.rm = TRUE) #mean ignoring NA values\nprint(before_mean) #Mean before handling NA values\n\n[1] 2.301754\n\nbefore_sd &lt;- sd(na_example, na.rm = TRUE)  #standard deviation ignoring NA values\nprint(before_sd) #Standard Deviation before handling NA values\n\n[1] 1.22338\n\nmedian_value &lt;- median(na_example, na.rm = TRUE) # Compute the median of non-missing values\n\n\nna_replaced_median &lt;- na_example\nna_replaced_median[is.na(na_replaced_median)] &lt;- median_value # Replace NA values with the median\n\n\nnon_na_values &lt;- na_example[!is.na(na_example)]\nrandom_values &lt;- sample(non_na_values, size = sum(is.na(na_example)), replace = TRUE) # Select a random non-missing value\n\n\nna_replaced_random &lt;- na_example\nna_replaced_random[is.na(na_replaced_random)] &lt;- random_values # Replace NA values with random values\n\n\n# Version 1 (NA replaced with median)\nmean_median &lt;- mean(na_replaced_median)  #mean- NA replaced with median\nprint(mean_median)   #Mean after replacing NA with median\n\n[1] 2.258\n\nsd_median &lt;- sd(na_replaced_median)  #standard deviation- NA replaced with median\nprint(sd_median)  # Standard Deviation after replacing NA with median\n\n[1] 1.136102\n\n# Version 2 (NA replaced with random values)\nmean_random &lt;- mean(na_replaced_random)\nprint(mean_random) #Mean after replacing NA with random values\n\n[1] 2.312\n\nsd_random &lt;- sd(na_replaced_random)\nprint(sd_random) #Standard Deviation after replacing NA with random values\n\n[1] 1.228073\n\n\"Yorumlar\"\n\n[1] \"Yorumlar\"\n\n\"Bu veri seti için eksik verilerin rastgele mevcut değerlerle doldurulması yöntemi daha uygun görünmektedir. Bunun nedeni, bu yöntemin veri setinin ortalama ve standart sapma değerlerini koruyarak orijinal veri yapısının bozulmasını en aza indirmesidir. Öte yandan, medyan ile doldurma yöntemi veri setinin varyansını azaltarak veri dağılımını değiştirmiş ve olası bilgi kaybına neden olmuştur.\"\n\n[1] \"Bu veri seti için eksik verilerin rastgele mevcut değerlerle doldurulması yöntemi daha uygun görünmektedir. Bunun nedeni, bu yöntemin veri setinin ortalama ve standart sapma değerlerini koruyarak orijinal veri yapısının bozulmasını en aza indirmesidir. Öte yandan, medyan ile doldurma yöntemi veri setinin varyansını azaltarak veri dağılımını değiştirmiş ve olası bilgi kaybına neden olmuştur.\"",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "project.html#economic-indicators-20212023",
    "href": "project.html#economic-indicators-20212023",
    "title": "An Empirical Analysis of the Effects of Inflation and Exchange Rate Volatility on Brain Drain in Turkey (2021–2023)",
    "section": "2.1 Economic Indicators (2021–2023)",
    "text": "2.1 Economic Indicators (2021–2023)\nThe data within this category were obtained from reliable and up-to-date statistics published by the Turkish Statistical Institute (TÜİK) and the Central Bank of the Republic of Turkey (CBRT). The following variables were included in the analysis:\nAnnual Inflation Rates: Calculated based on the year-on-year percentage change of the Consumer Price Index (CPI) using December as the reference month.\nExchange Rates: Represent the annual average value of the Turkish Lira against the US Dollar.\nUnemployment Rates: Incorporated into the modeling as a control variable, subject to availability.\nThese indicators were integrated with the brain drain data and utilized as independent variables in statistical modeling processes."
  },
  {
    "objectID": "project.html#brain-drain-data-20152023",
    "href": "project.html#brain-drain-data-20152023",
    "title": "An Empirical Analysis of the Effects of Inflation and Exchange Rate Volatility on Brain Drain in Turkey (2021–2023)",
    "section": "2.2 Brain Drain Data (2015–2023)",
    "text": "2.2 Brain Drain Data (2015–2023)\nThis dataset, covering emigration movements of individuals with higher education degrees from Turkey, was obtained from the “Higher Education Brain Drain Statistics” published by TÜİK as of 2023. The data were structured to enable detailed analyses across the following dimensions:\nMigration rates by graduation year (for graduates between 2000 and 2017),\nMigration rates by gender (male/female distribution),\nMigration rates by field of education (e.g., engineering, information technologies, health sciences, social sciences),\nMigration rates by academic major (e.g., computer engineering, molecular biology),\nDistribution by destination countries (e.g., USA, Germany, Netherlands, Canada),\nDistribution of the top five academic majors for the top five destination countries (country-major pairings).\nIn addition to providing quantitative intensities, this dataset enables the identification of qualitative characteristics of the emigrating population. Particularly, the concentration of migration within STEM (science, technology, engineering, and mathematics) fields is of critical importance for understanding the sectoral structure of Turkey’s skilled labor outflow.\nThe data were originally obtained in .xlsx format and processed using the R programming language. The preprocessing steps included data cleaning, removal of missing and outlier observations, recoding of categorical variables, and transformation of numerical variables. To ensure consistency, cross-referencing and alignment of variables such as year, academic major, and destination country were performed across datasets. The final, consolidated dataset was saved in .RData format to ensure the accuracy and reproducibility of the subsequent analyses. This preprocessing phase plays a crucial role in guaranteeing the integrity and scientific robustness of the study."
  }
]